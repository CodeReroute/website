import React from 'react';

export default function CSAEStandardsPage() {
  return (
    <main
      style={{
        maxWidth: '960px',
        margin: '0 auto',
        padding: '3rem 1.5rem',
        fontFamily:
          'system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif',
        lineHeight: 1.6,
      }}
    >
      <header style={{ marginBottom: '2.5rem' }}>
        <h1
          style={{
            fontSize: '2.2rem',
            fontWeight: 700,
            marginBottom: '0.75rem',
          }}
        >
          Standards on Child Sexual Abuse and Exploitation (CSAE)
        </h1>
        <p style={{ fontSize: '1rem', color: '#4b5563', maxWidth: '720px' }}>
          This page describes how our social media service prevents, detects,
          and responds to child sexual abuse and exploitation (CSAE). It is
          intended for users, caregivers, partners, and regulators who need a
          clear view of our externally published standards.
        </p>
      </header>

      <section style={{ marginBottom: '2rem' }}>
        <h2
          style={{
            fontSize: '1.4rem',
            fontWeight: 600,
            marginBottom: '0.75rem',
          }}
        >
          1. Zero‑tolerance policy
        </h2>
        <p>
          We operate a strict zero‑tolerance policy towards all forms of child
          sexual abuse and exploitation. This includes, but is not limited to:
        </p>
        <ul style={{ margin: '0.75rem 0 0 1.25rem', listStyle: 'disc' }}>
          <li>
            CSAM (child sexual abuse material), in any format (image, video,
            audio, text).
          </li>
          <li>
            Sexualized depictions of children, including fictionalized or
            AI‑generated content.
          </li>
          <li>
            Grooming, coercion, or solicitation of children for sexual purposes.
          </li>
          <li>
            Sexual extortion, trafficking, or any commercial sexual exploitation
            of children.
          </li>
          <li>
            Instructions, fantasies, or encouragement of CSAE, including in
            private spaces.
          </li>
        </ul>
        <p style={{ marginTop: '0.75rem' }}>
          Where legally required or appropriate, we report detected CSAE content
          and accounts to relevant law‑enforcement bodies or hotlines.
        </p>
      </section>

      <section style={{ marginBottom: '2rem' }}>
        <h2
          style={{
            fontSize: '1.4rem',
            fontWeight: 600,
            marginBottom: '0.75rem',
          }}
        >
          2. Definition of a child
        </h2>
        <p>
          For the purposes of these standards, a <strong>child</strong> is any
          person under the age of 18, regardless of local age‑of‑majority or
          consent laws, unless a stricter local definition applies.
        </p>
      </section>

      <section style={{ marginBottom: '2rem' }}>
        <h2
          style={{
            fontSize: '1.4rem',
            fontWeight: 600,
            marginBottom: '0.75rem',
          }}
        >
          3. Prohibited content and behavior
        </h2>
        <p>The following are strictly prohibited on our service:</p>
        <ul style={{ margin: '0.75rem 0 0 1.25rem', listStyle: 'disc' }}>
          <li>
            Any media that depicts the sexual abuse or exploitation of a child,
            including nudity or sexualized posing where a reasonable person
            would understand the content to be sexual.
          </li>
          <li>
            Sexual discussions, fantasies, or role‑play involving real or
            purported children, even if participants claim to be adults.
          </li>
          <li>
            Grooming behavior, including attempts to move a child to more
            private channels, requests for sexual images, or offers of money,
            gifts, or favors in exchange for sexual activity.
          </li>
          <li>
            Use of our service to advertise, facilitate, or profit from
            trafficking, live‑streamed abuse, or other forms of CSAE.
          </li>
          <li>
            Links or instructions to access CSAE content off‑platform, including
            via encrypted services, file‑sharing sites, or hidden services.
          </li>
        </ul>
        <p style={{ marginTop: '0.75rem' }}>
          We may also restrict non‑sexual content involving children (for
          example, partial nudity in non‑abusive contexts) when it is likely to
          be misused, taken out of context, or when required by local law or
          industry best practice.
        </p>
      </section>

      <section style={{ marginBottom: '2rem' }}>
        <h2
          style={{
            fontSize: '1.4rem',
            fontWeight: 600,
            marginBottom: '0.75rem',
          }}
        >
          4. Detection, review, and reporting
        </h2>
        <p>
          We use a combination of technology, human review, and user reports to
          detect and respond to CSAE:
        </p>
        <ul style={{ margin: '0.75rem 0 0 1.25rem', listStyle: 'disc' }}>
          <li>
            Industry‑standard hashing and matching technologies to detect known
            CSAM where legally permitted.
          </li>
          <li>
            Safety and integrity systems to identify suspicious behavior
            patterns such as repeated contact with minors, mass messaging, or
            attempts to circumvent blocks.
          </li>
          <li>
            Dedicated trust &amp; safety review processes for escalated cases
            involving potential CSAE.
          </li>
          <li>
            Mandatory or discretionary reports to law enforcement and relevant
            hotlines, consistent with applicable law and our legal obligations.
          </li>
        </ul>
        <p style={{ marginTop: '0.75rem' }}>
          These systems are continuously evaluated and improved. We may apply
          stricter controls in regions or contexts where risk is higher.
        </p>
      </section>

      <section style={{ marginBottom: '2rem' }}>
        <h2
          style={{
            fontSize: '1.4rem',
            fontWeight: 600,
            marginBottom: '0.75rem',
          }}
        >
          5. Enforcement actions
        </h2>
        <p>
          When we identify or reasonably believe that a user has engaged in CSAE
          or violated these standards, we may take one or more of the following
          actions:
        </p>
        <ul style={{ margin: '0.75rem 0 0 1.25rem', listStyle: 'disc' }}>
          <li>Immediate removal of content from the service.</li>
          <li>Account suspension or permanent account termination.</li>
          <li>
            Restrictions on creating new accounts or accessing certain features.
          </li>
          <li>
            Preservation of data and reporting to law enforcement or child
            protection organizations, where appropriate and legally permitted.
          </li>
          <li>
            Cooperation with lawful information requests from competent
            authorities in line with our privacy and data‑protection
            obligations.
          </li>
        </ul>
      </section>

      <section style={{ marginBottom: '2rem' }}>
        <h2
          style={{
            fontSize: '1.4rem',
            fontWeight: 600,
            marginBottom: '0.75rem',
          }}
        >
          6. Protecting young users
        </h2>
        <p>
          Beyond removing CSAE content, we aim to reduce the risk of harm to
          children on our service through product design and safeguards, which
          may include:
        </p>
        <ul style={{ margin: '0.75rem 0 0 1.25rem', listStyle: 'disc' }}>
          <li>
            Age‑appropriate experiences and restrictions for younger users,
            where available.
          </li>
          <li>
            Limitations on who can contact or find accounts that are likely to
            belong to minors.
          </li>
          <li>
            Stronger defaults for privacy, visibility, and contact settings for
            young users.
          </li>
          <li>
            Prompts, safety notices, and reporting tools that are understandable
            to minors.
          </li>
        </ul>
      </section>

      <section style={{ marginBottom: '2rem' }}>
        <h2
          style={{
            fontSize: '1.4rem',
            fontWeight: 600,
            marginBottom: '0.75rem',
          }}
        >
          7. User reporting and support
        </h2>
        <p>
          If you encounter content or behavior that you believe involves CSAE,
          you should report it using our in‑product tools (where available) and,
          if safe to do so, to your local law‑enforcement authority. When we
          receive a report:
        </p>
        <p style={{ marginTop: '0.75rem' }}>
          Mappetizer allows users to report child safety concerns directly in
          the app. To learn more about reporting requirements, visit the Help
          Center.
        </p>
        <p style={{ marginTop: '0.75rem' }}>
          Mappetizer complies with all relevant child safety laws and reports to
          appropriate regional and national authorities, where required and
          permitted by law. To learn more about reporting to the relevant
          authorities, visit the Help Center.
        </p>
        <ul style={{ margin: '0.75rem 0 0 1.25rem', listStyle: 'disc' }}>
          <li>
            We review the report as quickly as possible, prioritizing CSAE and
            safety risks.
          </li>
          <li>
            We remove content, restrict accounts, or escalate to law enforcement
            as needed.
          </li>
          <li>
            We may limit the information we share about enforcement outcomes to
            protect the privacy and safety of those involved.
          </li>
        </ul>
      </section>

      <section style={{ marginBottom: '2rem' }}>
        <h2
          style={{
            fontSize: '1.4rem',
            fontWeight: 600,
            marginBottom: '0.75rem',
          }}
        >
          8. Transparency and updates
        </h2>
        <p>
          We may publish high‑level transparency information about how we
          enforce these standards, such as metrics on the volume of content
          removed or accounts actioned for CSAE, where it is safe and lawful to
          do so.
        </p>
        <p style={{ marginTop: '0.75rem' }}>
          These standards may be updated over time to reflect changes in law,
          best practices, technology, and our products. Significant changes will
          be reflected on this page with an updated effective date.
        </p>
      </section>

      <section style={{ marginBottom: '2rem' }}>
        <h2
          style={{
            fontSize: '1.4rem',
            fontWeight: 600,
            marginBottom: '0.75rem',
          }}
        >
          9. Jurisdiction and legal notice
        </h2>
        <p>
          This document is intended as a high‑level description of our
          externally published standards regarding CSAE on our service. It does
          not limit any rights we may have under our Terms of Service, Community
          Guidelines, or applicable law, and it does not create third‑party
          beneficiary rights.
        </p>
      </section>

      <footer
        style={{ marginTop: '3rem', fontSize: '0.9rem', color: '#6b7280' }}
      >
        <p>
          <strong>Important:</strong> If a child is in immediate danger, contact
          your local emergency services or law‑enforcement authority before
          reporting the content to us.
        </p>
        <p style={{ marginTop: '0.5rem' }}>
          This page is provided for transparency and compliance purposes and may
          be shared via direct link.
        </p>
      </footer>
    </main>
  );
}
